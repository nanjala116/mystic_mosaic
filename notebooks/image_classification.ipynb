{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification with Transfer Learning\n",
    "### This notebook trains a CNN-based classifier to distinguish between cats and dogs.\n",
    "\n",
    "**Dataset:**  \n",
    "The dataset has been imported from Kaggle, the cats and dogs dataset\n",
    "\n",
    "**Approach:**  \n",
    "We use an object-oriented approach with TensorFlow/Keras and transfer learning \n",
    "(using EfficientNetB0) to achieve at least 90% accuracy.\n",
    "\n",
    "**Deliverables:**\n",
    "- Trained model saved as `../models/cnn_model.h5`\n",
    "- This notebook (`image_classification.ipynb`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n",
      "OpenCV version: 4.11.0\n",
      "Pillow (PIL) version: 11.1.0\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.layers import Rescaling\n",
    "\n",
    "\n",
    "def check_versions():\n",
    "    \"\"\"Print version information for key libraries.\"\"\"\n",
    "    print(f\"TensorFlow version: {tf.__version__}\")\n",
    "    print(f\"OpenCV version: {cv2.__version__}\")\n",
    "    print(f\"Pillow (PIL) version: {Image.__version__}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    check_versions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ImageClassifier class\n",
    "class RobustImageClassifier:\n",
    "    def __init__(self, data_dir, img_size=(224, 224), batch_size=16, val_split=0.2, seed=42):\n",
    "        self.data_dir = data_dir\n",
    "        self.img_size = img_size\n",
    "        self.batch_size = batch_size  # Reduced default batch size\n",
    "        self.val_split = val_split\n",
    "        self.seed = seed\n",
    "        self.train_ds = None\n",
    "        self.val_ds = None\n",
    "        self.model = None\n",
    "        self.corrupted_files = []\n",
    "        self._verified_images = set()\n",
    "\n",
    "    def _validate_image_file(self, file_path):\n",
    "        \"\"\"Thoroughly validate an image file using both PIL and TensorFlow.\"\"\"\n",
    "        if file_path in self._verified_images:\n",
    "            return True\n",
    "            \n",
    "        try:\n",
    "            # First check with PIL\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()  # Verify file integrity\n",
    "                if len(img.getbands()) not in [1, 3]:\n",
    "                    print(f\"Invalid channels in {file_path}\")\n",
    "                    return False\n",
    "                \n",
    "            # Then check with TensorFlow\n",
    "            img_data = tf.io.read_file(file_path)\n",
    "            img = tf.image.decode_image(img_data, channels=3, expand_animations=False)\n",
    "            if img.shape.rank != 3 or img.shape[-1] not in [1, 3]:\n",
    "                print(f\"Invalid tensor shape in {file_path}\")\n",
    "                return False\n",
    "                \n",
    "            self._verified_images.add(file_path)\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Corrupted image detected: {file_path} - {str(e)}\")\n",
    "            self.corrupted_files.append(file_path)\n",
    "            return False\n",
    "\n",
    "    def clean_dataset(self):\n",
    "        \"\"\"Remove corrupted files and non-image files from dataset.\"\"\"\n",
    "        print(\"\\n=== Cleaning Dataset ===\")\n",
    "        removed_count = 0\n",
    "        valid_extensions = ('.jpg', '.jpeg', '.png')\n",
    "        \n",
    "        for root, _, files in os.walk(self.data_dir):\n",
    "            for file in files:\n",
    "                file_path = os.path.join(root, file)\n",
    "                \n",
    "                # Remove non-image files\n",
    "                if not file.lower().endswith(valid_extensions):\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        removed_count += 1\n",
    "                        print(f\"Removed non-image file: {file_path}\")\n",
    "                        continue\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing {file_path}: {str(e)}\")\n",
    "                        continue\n",
    "                \n",
    "                # Remove corrupted images\n",
    "                if not self._validate_image_file(file_path):\n",
    "                    try:\n",
    "                        os.remove(file_path)\n",
    "                        removed_count += 1\n",
    "                        print(f\"Removed corrupted image: {file_path}\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error removing corrupted file {file_path}: {str(e)}\")\n",
    "        \n",
    "        print(f\"\\nCleaning complete. Removed {removed_count} files.\")\n",
    "        print(f\"Found {len(self.corrupted_files)} corrupted images.\")\n",
    "        return removed_count\n",
    "\n",
    "    def _load_and_validate_image(self, file_path, label):\n",
    "        \"\"\"Robust image loading with comprehensive validation.\"\"\"\n",
    "        try:\n",
    "            # Read and decode with explicit error handling\n",
    "            img_data = tf.io.read_file(file_path)\n",
    "            img = tf.image.decode_image(img_data, channels=3, expand_animations=False)\n",
    "            \n",
    "            # Validate tensor properties\n",
    "            if img.shape.rank != 3 or img.shape[-1] not in [1, 3]:\n",
    "                raise ValueError(f\"Invalid tensor shape: {img.shape}\")\n",
    "                \n",
    "            # Convert and resize\n",
    "            img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "            img = tf.image.resize(img, self.img_size)\n",
    "            \n",
    "            # Ensure 3 channels\n",
    "            if img.shape[-1] == 1:  # Grayscale\n",
    "                img = tf.image.grayscale_to_rgb(img)\n",
    "            elif img.shape[-1] == 4:  # RGBA\n",
    "                img = img[..., :3]\n",
    "                \n",
    "            return img, label\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Skipping corrupted image {file_path}: {str(e)}\")\n",
    "            # Return zero tensor that will be filtered out\n",
    "            return tf.zeros((*self.img_size, 3)), label\n",
    "\n",
    "    def _filter_valid_images(self, img, label):\n",
    "        \"\"\"Filter out invalid images (all zeros).\"\"\"\n",
    "        return tf.reduce_sum(tf.abs(img)) > 0.0\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"Load dataset with robust validation and error handling.\"\"\"\n",
    "        print(\"\\n=== Loading Dataset ===\")\n",
    "        \n",
    "        # First build list of validated image paths\n",
    "        image_paths = []\n",
    "        labels = []\n",
    "        class_names = sorted(os.listdir(self.data_dir))\n",
    "        label_to_index = {name: i for i, name in enumerate(class_names)}\n",
    "        \n",
    "        for class_name in class_names:\n",
    "            class_dir = os.path.join(self.data_dir, class_name)\n",
    "            for file in os.listdir(class_dir):\n",
    "                if file.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                    file_path = os.path.join(class_dir, file)\n",
    "                    if self._validate_image_file(file_path):\n",
    "                        image_paths.append(file_path)\n",
    "                        labels.append(label_to_index[class_name])\n",
    "        \n",
    "        # Create dataset from validated paths\n",
    "        path_ds = tf.data.Dataset.from_tensor_slices((image_paths, labels))\n",
    "        \n",
    "        # Apply loading and filtering\n",
    "        image_ds = path_ds.map(\n",
    "            lambda x, y: self._load_and_validate_image(x, y),\n",
    "            num_parallel_calls=tf.data.AUTOTUNE\n",
    "        ).filter(self._filter_valid_images)\n",
    "        \n",
    "        # Shuffle and split\n",
    "        dataset_size = len(image_paths)\n",
    "        train_size = int((1 - self.val_split) * dataset_size)\n",
    "        \n",
    "        self.train_ds = (image_ds.take(train_size)\n",
    "                        .shuffle(1024, seed=self.seed)\n",
    "                        .batch(self.batch_size)\n",
    "                        .prefetch(tf.data.AUTOTUNE))\n",
    "        \n",
    "        self.val_ds = (image_ds.skip(train_size)\n",
    "                      .batch(self.batch_size)\n",
    "                      .prefetch(tf.data.AUTOTUNE))\n",
    "        \n",
    "        print(f\"Successfully loaded {dataset_size} valid images \"\n",
    "              f\"({train_size} training, {dataset_size - train_size} validation)\")\n",
    "        return self.train_ds, self.val_ds\n",
    "\n",
    "    def build_model(self, fine_tune_at=100):\n",
    "        \"\"\"\n",
    "        Build transfer learning model with EfficientNetB0 base.\n",
    "        Includes input validation and automatic channel handling.\n",
    "        \"\"\"\n",
    "        # Input validation\n",
    "        if not isinstance(self.img_size, tuple) or len(self.img_size) != 2:\n",
    "            raise ValueError(\"img_size must be a tuple of (height, width)\")\n",
    "        \n",
    "        print(\"\\n=== Building Model ===\")\n",
    "        try:\n",
    "            base_model = EfficientNetB0(\n",
    "                weights=\"imagenet\",\n",
    "                include_top=False,\n",
    "                input_shape=(*self.img_size, 3)\n",
    "            )\n",
    "            base_model.trainable = False\n",
    "\n",
    "            inputs = tf.keras.Input(shape=(*self.img_size, 3))\n",
    "            x = layers.Rescaling(1./255)(inputs)\n",
    "            x = base_model(x, training=False)\n",
    "            x = layers.GlobalAveragePooling2D()(x)\n",
    "            x = layers.Dropout(0.2)(x)\n",
    "            outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "            \n",
    "            self.model = tf.keras.Model(inputs, outputs)\n",
    "            \n",
    "            self.model.compile(\n",
    "                optimizer=optimizers.Adam(),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "            \n",
    "            print(\"Model built successfully!\")\n",
    "            return self.model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error building model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def fine_tune_model(self, fine_tune_at=100):\n",
    "        \"\"\"Unfreeze layers for fine-tuning with validation.\"\"\"\n",
    "        if not hasattr(self, 'model') or self.model is None:\n",
    "            raise ValueError(\"Model must be built before fine-tuning\")\n",
    "            \n",
    "        print(\"\\n=== Fine-Tuning Model ===\")\n",
    "        try:\n",
    "            base_model = self.model.layers[2]\n",
    "            base_model.trainable = True\n",
    "            for layer in base_model.layers[:fine_tune_at]:\n",
    "                layer.trainable = False\n",
    "                \n",
    "            self.model.compile(\n",
    "                optimizer=optimizers.Adam(1e-5),\n",
    "                loss=\"binary_crossentropy\",\n",
    "                metrics=[\"accuracy\"]\n",
    "            )\n",
    "            print(\"Model ready for fine-tuning!\")\n",
    "            return self.model\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error configuring fine-tuning: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def train_model(self, epochs=10):\n",
    "        \"\"\"Train model with comprehensive error handling and callbacks.\"\"\"\n",
    "        if self.train_ds is None or self.val_ds is None:\n",
    "            raise ValueError(\"Data must be loaded before training\")\n",
    "            \n",
    "        print(\"\\n=== Training Model ===\")\n",
    "        try:\n",
    "            os.makedirs(\"models\", exist_ok=True)\n",
    "            callbacks = [\n",
    "                EarlyStopping(monitor=\"val_accuracy\", patience=3, restore_best_weights=True),\n",
    "                ModelCheckpoint(\n",
    "                    \"models/best_model.h5\",\n",
    "                    monitor=\"val_accuracy\",\n",
    "                    save_best_only=True,\n",
    "                    save_weights_only=False\n",
    "                )\n",
    "            ]\n",
    "            \n",
    "            history = self.model.fit(\n",
    "                self.train_ds,\n",
    "                validation_data=self.val_ds,\n",
    "                epochs=epochs,\n",
    "                callbacks=callbacks,\n",
    "                verbose=1\n",
    "            )\n",
    "            \n",
    "            print(\"\\nTraining completed successfully!\")\n",
    "            return history\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nTraining failed: {str(e)}\")\n",
    "            print(\"Possible solutions:\")\n",
    "            print(\"- Reduce batch size if memory error\")\n",
    "            print(\"- Check image dimensions and channels\")\n",
    "            print(\"- Verify dataset contains valid images\")\n",
    "            raise\n",
    "\n",
    "    def evaluate_model(self):\n",
    "        \"\"\"Evaluate model with proper validation checks.\"\"\"\n",
    "        if self.val_ds is None:\n",
    "            raise ValueError(\"Validation data not loaded\")\n",
    "            \n",
    "        print(\"\\n=== Evaluating Model ===\")\n",
    "        try:\n",
    "            loss, accuracy = self.model.evaluate(self.val_ds, verbose=1)\n",
    "            print(f\"Validation Loss: {loss:.4f}\")\n",
    "            print(f\"Validation Accuracy: {accuracy:.4f}\")\n",
    "            return loss, accuracy\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Evaluation failed: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def save_model(self, filepath=\"models/cnn_model.h5\"):\n",
    "        \"\"\"Save model with path validation.\"\"\"\n",
    "        try:\n",
    "            os.makedirs(os.path.dirname(filepath), exist_ok=True)\n",
    "            self.model.save(filepath)\n",
    "            print(f\"Model successfully saved to {filepath}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {str(e)}\")\n",
    "            raise\n",
    "\n",
    "    def get_corrupted_files(self):\n",
    "        \"\"\"Return list of detected corrupted files.\"\"\"\n",
    "        return self.corrupted_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Starting Robust Training Pipeline ===\n",
      "\n",
      "=== Cleaning Dataset ===\n",
      "\n",
      "=== Cleaning Dataset ===\n",
      "Corrupted image detected: ../data/pet_images\\Cat\\4351.jpg - {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input size should match (header_size + row_size * abs_height) but they differ by 2 [Op:DecodeImage] name: \n",
      "Removed corrupted image: ../data/pet_images\\Cat\\4351.jpg\n",
      "Corrupted image detected: ../data/pet_images\\Dog\\11233.jpg - {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
      "Removed corrupted image: ../data/pet_images\\Dog\\11233.jpg\n",
      "Corrupted image detected: ../data/pet_images\\Dog\\11912.jpg - {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
      "Removed corrupted image: ../data/pet_images\\Dog\\11912.jpg\n",
      "Corrupted image detected: ../data/pet_images\\Dog\\2317.jpg - {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
      "Removed corrupted image: ../data/pet_images\\Dog\\2317.jpg\n",
      "Corrupted image detected: ../data/pet_images\\Dog\\2494.jpg - {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Input size should match (header_size + row_size * abs_height) but they differ by 2 [Op:DecodeImage] name: \n",
      "Removed corrupted image: ../data/pet_images\\Dog\\2494.jpg\n",
      "Corrupted image detected: ../data/pet_images\\Dog\\9500.jpg - {{function_node __wrapped__DecodeImage_device_/job:localhost/replica:0/task:0/device:CPU:0}} Number of channels inherent in the image must be 1, 3 or 4, was 2 [Op:DecodeImage] name: \n",
      "Removed corrupted image: ../data/pet_images\\Dog\\9500.jpg\n",
      "\n",
      "Cleaning complete. Removed 6 files.\n",
      "Found 6 corrupted images.\n",
      "Removed 6 problematic files. Please verify your dataset.\n",
      "\n",
      "=== Loading Data ===\n",
      "\n",
      "=== Loading Dataset ===\n",
      "Successfully loaded 24953 valid images (19962 training, 4991 validation)\n",
      "\n",
      "Sample batch verification:\n",
      "Images shape: (16, 224, 224, 3), dtype: <dtype: 'float32'>\n",
      "Labels shape: (16,), unique values: [0]\n",
      "\n",
      "=== Building Model ===\n",
      "\n",
      "=== Building Model ===\n",
      "Model built successfully!\n",
      "\n",
      "=== Training Model ===\n",
      "\n",
      "=== Training Model ===\n",
      "Epoch 1/5\n",
      "   1248/Unknown \u001b[1m533s\u001b[0m 416ms/step - accuracy: 0.9828 - loss: 0.0593"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ZAWADI\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\trainers\\epoch_iterator.py:151: UserWarning: Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches. You may need to use the `.repeat()` function when building your dataset.\n",
      "  self._interrupted_warning()\n",
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m680s\u001b[0m 534ms/step - accuracy: 0.9828 - loss: 0.0593 - val_accuracy: 1.0000 - val_loss: 0.0016\n",
      "Epoch 2/5\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m623s\u001b[0m 499ms/step - accuracy: 0.9383 - loss: 0.2376 - val_accuracy: 1.0000 - val_loss: 0.0027\n",
      "Epoch 3/5\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m653s\u001b[0m 523ms/step - accuracy: 0.9386 - loss: 0.2268 - val_accuracy: 1.0000 - val_loss: 0.0020\n",
      "Epoch 4/5\n",
      "\u001b[1m1248/1248\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m614s\u001b[0m 491ms/step - accuracy: 0.9371 - loss: 0.2414 - val_accuracy: 1.0000 - val_loss: 0.0025\n",
      "\n",
      "Training completed successfully!\n",
      "\n",
      "=== Evaluation ===\n",
      "\n",
      "=== Evaluating Model ===\n",
      "\u001b[1m312/312\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 383ms/step - accuracy: 1.0000 - loss: 0.0016\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.0016\n",
      "Validation Accuracy: 1.0000\n",
      "\n",
      "=== Saving Model ===\n",
      "Model successfully saved to ../models/robust_cnn_model.h5\n",
      "\n",
      "=== Pipeline Completed Successfully ===\n",
      "\n",
      "Final validation accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Define the workflow for robust training\n",
    "def main():\n",
    "    \"\"\"Robust training workflow with comprehensive error handling.\"\"\"\n",
    "    config = {\n",
    "        \"data_dir\": \"../data/pet_images\",\n",
    "        \"img_size\": (224, 224),\n",
    "        \"batch_size\": 16,  # Reduced for stability\n",
    "        \"val_split\": 0.2,\n",
    "        \"initial_epochs\": 5,  # Start with fewer epochs\n",
    "        \"target_accuracy\": 0.90,\n",
    "        \"model_save_path\": \"../models/robust_cnn_model.h5\"\n",
    "    }\n",
    "\n",
    "    print(\"\\n=== Starting Robust Training Pipeline ===\")\n",
    "    \n",
    "    try:\n",
    "        # Initialize with enhanced classifier\n",
    "        classifier = RobustImageClassifier(\n",
    "            data_dir=config[\"data_dir\"],\n",
    "            img_size=config[\"img_size\"],\n",
    "            batch_size=config[\"batch_size\"],\n",
    "            val_split=config[\"val_split\"]\n",
    "        )\n",
    "        \n",
    "        # Clean dataset thoroughly\n",
    "        print(\"\\n=== Cleaning Dataset ===\")\n",
    "        cleaned = classifier.clean_dataset()\n",
    "        if cleaned > 0:\n",
    "            print(f\"Removed {cleaned} problematic files. Please verify your dataset.\")\n",
    "        \n",
    "        # Load data with validation\n",
    "        print(\"\\n=== Loading Data ===\")\n",
    "        train_ds, val_ds = classifier.load_data()\n",
    "        \n",
    "        # Quick verification\n",
    "        print(\"\\nSample batch verification:\")\n",
    "        for images, labels in train_ds.take(1):\n",
    "            print(f\"Images shape: {images.shape}, dtype: {images.dtype}\")\n",
    "            print(f\"Labels shape: {labels.shape}, unique values: {np.unique(labels.numpy())}\")\n",
    "        \n",
    "        # Build and train model\n",
    "        print(\"\\n=== Building Model ===\")\n",
    "        classifier.build_model()\n",
    "        \n",
    "        print(\"\\n=== Training Model ===\")\n",
    "        history = classifier.train_model(epochs=config[\"initial_epochs\"])\n",
    "        \n",
    "        # Evaluation\n",
    "        print(\"\\n=== Evaluation ===\")\n",
    "        loss, accuracy = classifier.evaluate_model()\n",
    "        \n",
    "        # Save model\n",
    "        print(\"\\n=== Saving Model ===\")\n",
    "        classifier.save_model(config[\"model_save_path\"])\n",
    "        \n",
    "        print(\"\\n=== Pipeline Completed Successfully ===\")\n",
    "        return history, accuracy\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(\"\\n=== Pipeline Failed ===\")\n",
    "        print(f\"Error: {str(e)}\")\n",
    "        print(\"\\nRecommended Actions:\")\n",
    "        print(\"1. Check the problematic_files list in the classifier\")\n",
    "        print(\"2. Manually verify the images mentioned in the error logs\")\n",
    "        print(\"3. Consider reducing batch size further if memory issues persist\")\n",
    "        print(\"4. Try with a smaller subset of data to isolate the issue\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        history, accuracy = main()\n",
    "        print(f\"\\nFinal validation accuracy: {accuracy:.2%}\")\n",
    "    except Exception as e:\n",
    "        print(\"\\nTraining failed. Please address the issues and try again.\")\n",
    "        print(f\"Last error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
