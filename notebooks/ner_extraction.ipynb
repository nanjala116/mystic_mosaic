{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition (NER) Comparison\n",
    "#### Comparing SpaCy vs. Hugging Face for entity extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.19.0\n"
     ]
    }
   ],
   "source": [
    "# Import libraries \n",
    "import os\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "from transformers import pipeline\n",
    "from itertools import groupby\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 text samples\n",
      "1. ﻿\"I recently purchased a MacBook from Apple, and the experience was great. The customer service at their New York store was excellent.\"\n",
      "2. \"The Tesla Model S is an amazing car. I bought it in San Francisco last year.\"\n",
      "3. \"Microsoft is doing great things with Azure and AI.\"\n"
     ]
    }
   ],
   "source": [
    "# Verify data path exists\n",
    "data_path = Path('../data/reviews.txt')\n",
    "if not data_path.exists():\n",
    "    raise FileNotFoundError(f\"Could not find data file at {data_path}\")\n",
    "\n",
    "# Read the text file\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    texts = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "print(f\"Loaded {len(texts)} text samples\")\n",
    "for i, text in enumerate(texts[:3], 1):\n",
    "    print(f\"{i}. {text}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Option 1: SpaCy Implementation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SpaCy Results (Sample):\n",
      "\n",
      "Text: ﻿\"I recently purchased a MacBook from Apple, and the experience was great. The customer service at their New York store was excellent.\"\n",
      "  ﻿\"I (ORG)\n",
      "  MacBook from Apple (ORG)\n",
      "  New York (GPE)\n",
      "\n",
      "Text: \"The Tesla Model S is an amazing car. I bought it in San Francisco last year.\"\n",
      "  The Tesla Model S (WORK_OF_ART)\n",
      "  San Francisco (GPE)\n",
      "  last year (DATE)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ﻿&quot;I\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " recently purchased a \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MacBook from Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and the experience was great. The customer service at their \n",
       "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " store was excellent.&quot;</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load SpaCy's pre-trained model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def spacy_ner(text):\n",
    "    \"\"\"Extract entities using SpaCy\"\"\"\n",
    "    doc = nlp(text)\n",
    "    return [(ent.text, ent.label_) for ent in doc.ents]\n",
    "\n",
    "# Process all texts\n",
    "spacy_results = []\n",
    "for text in texts:\n",
    "    entities = spacy_ner(text)\n",
    "    spacy_results.append({\n",
    "        'text': text,\n",
    "        'entities': entities\n",
    "    })\n",
    "\n",
    "# Display sample results\n",
    "print(\"\\nSpaCy Results (Sample):\")\n",
    "for result in spacy_results[:2]:\n",
    "    print(f\"\\nText: {result['text']}\")\n",
    "    for entity, label in result['entities']:\n",
    "        print(f\"  {entity} ({label})\")\n",
    "\n",
    "# Visualize\n",
    "doc = nlp(texts[0])\n",
    "displacy.render(doc, style=\"ent\", jupyter=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Improved SpaCy NER Results:\n",
      "\n",
      "Original: I recently purchased a MacBook from Apple, and the experience was great. The customer service at their New York store was excellent.\n",
      "Entities:\n",
      "  MacBook from Apple        (ORG)\n",
      "  New York                  (GPE)\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Original: The Tesla Model S is an amazing car. I bought it in San Francisco last year.\n",
      "Entities:\n",
      "  The Tesla Model S         (ORG)\n",
      "  San Francisco             (GPE)\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "Original: Microsoft is doing great things with Azure and AI.\n",
      "Entities:\n",
      "  Microsoft                 (ORG)\n",
      "  AI                        (GPE)\n",
      "\n",
      "--------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I recently purchased a \n",
       "<mark class=\"entity\" style=\"background: #ff9999; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    MacBook from Apple\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", and the experience was great. The customer service at their \n",
       "<mark class=\"entity\" style=\"background: #99ff99; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    New York\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
       "</mark>\n",
       " store was excellent.</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy import displacy\n",
    "from pathlib import Path\n",
    "\n",
    "# First ensure the model is installed\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"Downloading spaCy model...\")\n",
    "    !python -m spacy download en_core_web_sm\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Load your text file\n",
    "data_path = Path('../data/reviews.txt')\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    texts = [line.strip().replace('﻿\"', '\"').strip('\"') for line in f if line.strip()]\n",
    "\n",
    "def clean_ner_results(text, entities):\n",
    "    \"\"\"Clean up NER results by:\n",
    "    1. Removing unwanted characters\n",
    "    2. Merging broken entities\n",
    "    3. Filtering unwanted labels\"\"\"\n",
    "    cleaned = []\n",
    "    for ent in entities:\n",
    "        text = ent.text.strip('\"').strip()\n",
    "        label = ent.label_\n",
    "        \n",
    "        # Skip date entities if not needed\n",
    "        if label in ['DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY']:\n",
    "            continue\n",
    "            \n",
    "        cleaned.append((text, label))\n",
    "    return cleaned\n",
    "\n",
    "# Process texts with improved handling\n",
    "spacy_results = []\n",
    "for text in texts:\n",
    "    doc = nlp(text)\n",
    "    entities = clean_ner_results(doc, doc.ents)\n",
    "    spacy_results.append({\n",
    "        'text': text,\n",
    "        'entities': entities\n",
    "    })\n",
    "\n",
    "# Display cleaner results\n",
    "print(\"Improved SpaCy NER Results:\\n\")\n",
    "for result in spacy_results:\n",
    "    print(f\"Original: {result['text']}\")\n",
    "    if result['entities']:\n",
    "        print(\"Entities:\")\n",
    "        for entity, label in result['entities']:\n",
    "            print(f\"  {entity:<25} ({label})\")\n",
    "    else:\n",
    "        print(\"  No relevant entities found\")\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "# Visualize the first result with better formatting\n",
    "if len(spacy_results) > 0:\n",
    "    first_text = spacy_results[0]['text']\n",
    "    doc = nlp(first_text)\n",
    "    displacy.render(doc, style=\"ent\", jupyter=True, options={'colors': {'ORG': '#ff9999', 'GPE': '#99ff99'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running NER extraction...\n",
      "Processed 3 texts\n",
      "Results saved to ..\\data\\ner_results.txt\n",
      "Script saved to ..\\scripts\\ner_extraction.py\n"
     ]
    }
   ],
   "source": [
    "script_content = \"\"\"\n",
    "SpaCy NER Extraction Script\n",
    "\"\"\"\n",
    "\n",
    "def load_model():\n",
    "    try:\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "    except OSError:\n",
    "        import subprocess\n",
    "        import sys\n",
    "        subprocess.run([sys.executable, \"-m\", \"spacy\", \"download\", \"en_core_web_sm\"])\n",
    "        return spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_entities(text, nlp):\n",
    "    \"\"\"Extract and clean entities from text\"\"\"\n",
    "    doc = nlp(text)\n",
    "    entities = []\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ in ['DATE', 'TIME', 'PERCENT', 'MONEY', 'QUANTITY']:\n",
    "            continue\n",
    "        entities.append((ent.text.strip(), ent.label_))\n",
    "    return entities\n",
    "\n",
    "def process_file(input_path, output_path=None):\n",
    "    nlp = load_model()\n",
    "    \n",
    "    with open(input_path, 'r', encoding='utf-8') as f:\n",
    "        texts = [line.strip().replace('﻿\"', '\"').strip('\"') for line in f if line.strip()]\n",
    "    \n",
    "    results = []\n",
    "    for text in texts:\n",
    "        entities = extract_entities(text, nlp)\n",
    "        results.append({\n",
    "            'text': text,\n",
    "            'entities': entities\n",
    "        })\n",
    "        if output_path:\n",
    "            with open(output_path, 'a', encoding='utf-8') as f_out:\n",
    "                f_out.write(f\"Text: {text}\\\\n\")\n",
    "                for entity, label in entities:\n",
    "                    f_out.write(f\"  {entity:<25} ({label})\\\\n\")\n",
    "                f_out.write(\"\\\\n\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    input_file = Path('../data/reviews.txt')\n",
    "    output_file = Path('../data/ner_results.txt')\n",
    "    \n",
    "    print(\"Running NER extraction...\")\n",
    "    results = process_file(input_file, output_file)\n",
    "    print(f\"Processed {len(results)} texts\")\n",
    "    print(f\"Results saved to {output_file}\")\n",
    "\n",
    "\n",
    "# Save to file\n",
    "output_path = Path('../scripts/ner_extraction.py')\n",
    "output_path.parent.mkdir(exist_ok=True)\n",
    "with open(output_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(script_content)\n",
    "\n",
    "print(f\"Script saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
